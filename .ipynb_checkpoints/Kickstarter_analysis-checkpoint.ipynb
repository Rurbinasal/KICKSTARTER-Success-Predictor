{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding and Set-up\n",
    "Purpose: Ask relevant questions and define objectives for the problem that needs to be tackled\n",
    "## Key Question\n",
    "We are tasked by Kickstarter to come up with a model to predict viable targets for projects, in order for them to provide a good estimate for project creators (particularly as Kickstarter can influence certain parameters such as staff picks). \n",
    "* What would be a reasonable target **after the project creator enters key parameters**?\n",
    "* What would be a reasonable adapted target **after Kickstarter specifies its parameters (e.g. spotlight, staff pick)**?\n",
    "\n",
    "\n",
    "## Glossary\n",
    "* **TARGET: SUCCESS** - New column with 1 for success, 0 for fail (alternative for target: converted_pledged_amount)\n",
    "* **backers_count** - The number of supporters that actually invested in the project\n",
    "* **blurb** - \n",
    "* **category** - Main category the project falls in (e.g. \"food\", \"music\")\n",
    "* **converted_pledged_amount** - Pledged amount of USD realised at the deadline, converted from \"pledged\" via \"static_usd_rate\", rounded\n",
    "* **country** - Country of origin of the project\n",
    "* **created_at** - \n",
    "* **creator** - \n",
    "* **currency** - Currency of the project (e.g. USD, GBP)\n",
    "* **currency_symbol** - \n",
    "* **currency_trailing_code** - \n",
    "* **current_currency** - \n",
    "* **deadline** - Deadline of the project (can be used to analyze timeframes)\n",
    "* **disable_communication** - \n",
    "* **file** - \n",
    "* **friends** - \n",
    "* **fx_rate** - \n",
    "* **goal** - Amount of USD the project asked for initially\n",
    "* **id** - Project ID\n",
    "* **is_backing** - \n",
    "* **is_starrable** - \n",
    "* **is_starred** - \n",
    "* **launched_at** - Launch date of the project (can be used to analyze timeframes)\n",
    "* **location** - \n",
    "* **name** - Name of the project\n",
    "* **permissions** - \n",
    "* **photo** - \n",
    "* **pledged** - \n",
    "* **profile** - \n",
    "* **slug** - \n",
    "* **source_url** - \n",
    "* **spotlight** - \n",
    "* **staff_pick** - \n",
    "* **state** - Was the project successful at the end of the day? state is a categorical variable divided into the levels successful, failed, live, cancelled, undefined and suspended. For the sake of clarity, we will only look at whether a project was successful or failed (hence, we will remove all projects that are not classified as one of the two). Projects that failed or were successful make up around 88% of all projects.\n",
    "* **state_changed_at** - \n",
    "* **static_usd_rate** - \"Rate of conversion from \"currency\" to USD\n",
    "* **urls** - \n",
    "* **usd_pledged** - Pledged amount of USD realised at the deadline, converted from \"pledged\" via \"static_usd_rate\"\n",
    "* **usd_type** - ??? (NaN where \"current currency\" is not USD)\n",
    "\n",
    "## Variable Description\n",
    "* **data_raw** - Originally imported dataset\n",
    "* **data** - Main working dataset containing cleaned and refined data\n",
    "* **data_insp** - Copy of data before 3 Data Cleaning used during 3.1 Inspection\n",
    "* **data_clean** - Copy of data after 3 Data Cleaning used during 4 Data Exploration\n",
    "* **data_results** - Main working dataset incl. predicted values and residuals from selected regression model\n",
    "* **data_results_1..** - Interim results of the regression models\n",
    "* ...\n",
    "\n",
    "## Outcome/Recommendations\n",
    "- As per the key question, a) five high-grade and b) five sub-par investment opportunities have been identified\n",
    "- Optimal months to buy houses and year-on-year price movements still to be analyzed\n",
    "\n",
    "## To-Do-List\n",
    "- Is the data/csv's [monthly snapshot data](https://aito.ai/example-gallery/predict-and-explain-a-kickstarter-campaign-success/)? i.e., are the multiple ID entries just projects that span multiple months? Shouldn't they be more then?\n",
    "- Investigate TARGET: SUCCESS via \"state\": \n",
    "  - Should we drop all that are not successful or state?\n",
    "  - Is there a connection between \"canceled\", \"live\", \"suspended\" and the occurrence of multiple ID's?\n",
    "- Features:\n",
    "  - Column with avg backing per backer (converted_pledged_amount / backers_count)\n",
    "  - Calculate the #th project that it is for the specific person? (might be more successful if already submitted previous projects)\n",
    "- Is \"conv. pledged amount\" > \"goal\" the definitive criterion for \"state\"=successful?\n",
    "- What is usd_type domestic vs international vs NaN?\n",
    "- \"File\" stores the original csv file. Are there any issues with entries from particular files?\n",
    "- Anything useful in \"friends\", \"is_backing\", \"is_starred\", \"permissions\"?\n",
    "- Do we have duplicate projects? (yes, we have same IDs frequently. Maybe only keep the latest entry?)\n",
    "- Create timeseries/timeline\n",
    "- Gradient Descent?\n",
    "- Lasso?\n",
    "- Helpful links for solving: [Using ML to predict Kickstarter success](https://towardsdatascience.com/using-machine-learning-to-predict-kickstarter-success-e371ab56a743); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries (overarching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import overarching libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy as sc\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "\n",
    "#Subplots\n",
    "from plotly.subplots import make_subplots\n",
    "from numpy import median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining\n",
    "Purpose: Gather and scrape the data necessary for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from numpy import loadtxt\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import multiple csv files and merge into one dataframe\n",
    "all_files = glob.glob(os.path.join(\"data\", \"*.csv\"))\n",
    "all_df = []\n",
    "for f in all_files:\n",
    "    df = pd.read_csv(f, sep=',')\n",
    "    df['file'] = f.split('/')[-1]\n",
    "    all_df.append(df)\n",
    "data_raw = pd.concat(all_df, ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Assign data_raw to data\n",
    "data = data_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Purpose: Fix the inconsistencies within the data and handle the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from datetime import datetime\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection\n",
    "Purpose: Getting a good sense of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Clean dataset for inspection\n",
    "data_insp = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209222, 38)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display shape of \"data\"\n",
    "data_insp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>blurb</th>\n",
       "      <th>category</th>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>creator</th>\n",
       "      <th>currency</th>\n",
       "      <th>currency_symbol</th>\n",
       "      <th>currency_trailing_code</th>\n",
       "      <th>current_currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>disable_communication</th>\n",
       "      <th>file</th>\n",
       "      <th>friends</th>\n",
       "      <th>fx_rate</th>\n",
       "      <th>goal</th>\n",
       "      <th>id</th>\n",
       "      <th>is_backing</th>\n",
       "      <th>is_starrable</th>\n",
       "      <th>is_starred</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>permissions</th>\n",
       "      <th>photo</th>\n",
       "      <th>pledged</th>\n",
       "      <th>profile</th>\n",
       "      <th>slug</th>\n",
       "      <th>source_url</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>urls</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>usd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315</td>\n",
       "      <td>Babalus Shoes</td>\n",
       "      <td>{\"id\":266,\"name\":\"Footwear\",\"slug\":\"fashion/fo...</td>\n",
       "      <td>28645</td>\n",
       "      <td>US</td>\n",
       "      <td>1541459205</td>\n",
       "      <td>{\"id\":2094277840,\"name\":\"Lucy Conroy\",\"slug\":\"...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1552539775</td>\n",
       "      <td>False</td>\n",
       "      <td>Kickstarter040.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>2108505034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1548223375</td>\n",
       "      <td>{\"id\":2462429,\"name\":\"Novato\",\"slug\":\"novato-c...</td>\n",
       "      <td>Babalus Children's Shoes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/023/667/205/a565fde5382d6b53276...</td>\n",
       "      <td>28645.0</td>\n",
       "      <td>{\"id\":3508024,\"project_id\":3508024,\"state\":\"in...</td>\n",
       "      <td>babalus-childrens-shoes</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "      <td>1548223375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>28645.000000</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>A colorful Dia de los Muertos themed oracle de...</td>\n",
       "      <td>{\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...</td>\n",
       "      <td>1950</td>\n",
       "      <td>US</td>\n",
       "      <td>1501684093</td>\n",
       "      <td>{\"id\":723886115,\"name\":\"Lisa Vollrath\",\"slug\":...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1504976459</td>\n",
       "      <td>False</td>\n",
       "      <td>Kickstarter040.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>928751314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1502384459</td>\n",
       "      <td>{\"id\":2400549,\"name\":\"Euless\",\"slug\":\"euless-t...</td>\n",
       "      <td>The Ofrenda Oracle Deck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/017/766/989/dd9f18c773a8546d996...</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>{\"id\":3094785,\"project_id\":3094785,\"state\":\"ac...</td>\n",
       "      <td>the-ofrenda-oracle-deck</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1504976459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271</td>\n",
       "      <td>Electra's long awaited, eclectic Debut Pop/Roc...</td>\n",
       "      <td>{\"id\":43,\"name\":\"Rock\",\"slug\":\"music/rock\",\"po...</td>\n",
       "      <td>22404</td>\n",
       "      <td>US</td>\n",
       "      <td>1348987533</td>\n",
       "      <td>{\"id\":323849677,\"name\":\"Electra\",\"is_registere...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1371013395</td>\n",
       "      <td>False</td>\n",
       "      <td>Kickstarter040.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>928014092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1368421395</td>\n",
       "      <td>{\"id\":2423474,\"name\":\"Hollywood\",\"slug\":\"holly...</td>\n",
       "      <td>Record Electra's Debut Album (Pop, Rock, Class...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/011/433/681/489fd66f7861fefd8c8...</td>\n",
       "      <td>22404.0</td>\n",
       "      <td>{\"id\":359847,\"project_id\":359847,\"state\":\"inac...</td>\n",
       "      <td>record-electras-debut-album-pop-rock-classical</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1371013395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>22404.000000</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Mist of Tribunal is a turn-based card game...</td>\n",
       "      <td>{\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...</td>\n",
       "      <td>165</td>\n",
       "      <td>GB</td>\n",
       "      <td>1483780271</td>\n",
       "      <td>{\"id\":196281496,\"name\":\"Artur Ordijanc (delete...</td>\n",
       "      <td>GBP</td>\n",
       "      <td>£</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>1489425776</td>\n",
       "      <td>False</td>\n",
       "      <td>Kickstarter040.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.308394</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>596091328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1484245376</td>\n",
       "      <td>{\"id\":475457,\"name\":\"Kaunas\",\"slug\":\"kaunas-ka...</td>\n",
       "      <td>The Mist of Tribunal - A Card Game</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/015/091/198/216fbf1bdc3739e7971...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>{\"id\":2825329,\"project_id\":2825329,\"state\":\"in...</td>\n",
       "      <td>the-mist-of-tribunal-a-card-game</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>1489425776</td>\n",
       "      <td>1.216066</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>165.384934</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Livng with a brain impairment, what its like t...</td>\n",
       "      <td>{\"id\":48,\"name\":\"Nonfiction\",\"slug\":\"publishin...</td>\n",
       "      <td>2820</td>\n",
       "      <td>US</td>\n",
       "      <td>1354817071</td>\n",
       "      <td>{\"id\":1178460181,\"name\":\"Dawn Johnston\",\"is_re...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1357763527</td>\n",
       "      <td>False</td>\n",
       "      <td>Kickstarter040.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>998516049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1355171527</td>\n",
       "      <td>{\"id\":2507703,\"name\":\"Traverse City\",\"slug\":\"t...</td>\n",
       "      <td>Help change the face of Brain Impairment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/011/457/844/37ba63d35fefaba76e9...</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>{\"id\":417385,\"project_id\":417385,\"state\":\"inac...</td>\n",
       "      <td>help-change-the-face-of-brain-impairment</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1357763527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>2820.000000</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>Annapolis Chamber Players is a non-for profit ...</td>\n",
       "      <td>{\"id\":36,\"name\":\"Classical Music\",\"slug\":\"musi...</td>\n",
       "      <td>3725</td>\n",
       "      <td>US</td>\n",
       "      <td>1414172150</td>\n",
       "      <td>{\"id\":682189804,\"name\":\"Annapolis Chamber Play...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1430533546</td>\n",
       "      <td>False</td>\n",
       "      <td>Kickstarter040.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>1224600291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1427941546</td>\n",
       "      <td>{\"id\":2354877,\"name\":\"Annapolis\",\"slug\":\"annap...</td>\n",
       "      <td>Annapolis Chamber Music Project</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/011/921/106/c9ad5416f0b588b37b7...</td>\n",
       "      <td>3725.0</td>\n",
       "      <td>{\"id\":1465941,\"project_id\":1465941,\"state\":\"in...</td>\n",
       "      <td>annapolis-chamber-music-project</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1430533546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>3725.000000</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   backers_count                                              blurb  \\\n",
       "0            315                                      Babalus Shoes   \n",
       "1             47  A colorful Dia de los Muertos themed oracle de...   \n",
       "2            271  Electra's long awaited, eclectic Debut Pop/Roc...   \n",
       "3              3  The Mist of Tribunal is a turn-based card game...   \n",
       "4              3  Livng with a brain impairment, what its like t...   \n",
       "5             35  Annapolis Chamber Players is a non-for profit ...   \n",
       "\n",
       "                                            category  \\\n",
       "0  {\"id\":266,\"name\":\"Footwear\",\"slug\":\"fashion/fo...   \n",
       "1  {\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...   \n",
       "2  {\"id\":43,\"name\":\"Rock\",\"slug\":\"music/rock\",\"po...   \n",
       "3  {\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...   \n",
       "4  {\"id\":48,\"name\":\"Nonfiction\",\"slug\":\"publishin...   \n",
       "5  {\"id\":36,\"name\":\"Classical Music\",\"slug\":\"musi...   \n",
       "\n",
       "   converted_pledged_amount country  created_at  \\\n",
       "0                     28645      US  1541459205   \n",
       "1                      1950      US  1501684093   \n",
       "2                     22404      US  1348987533   \n",
       "3                       165      GB  1483780271   \n",
       "4                      2820      US  1354817071   \n",
       "5                      3725      US  1414172150   \n",
       "\n",
       "                                             creator currency currency_symbol  \\\n",
       "0  {\"id\":2094277840,\"name\":\"Lucy Conroy\",\"slug\":\"...      USD               $   \n",
       "1  {\"id\":723886115,\"name\":\"Lisa Vollrath\",\"slug\":...      USD               $   \n",
       "2  {\"id\":323849677,\"name\":\"Electra\",\"is_registere...      USD               $   \n",
       "3  {\"id\":196281496,\"name\":\"Artur Ordijanc (delete...      GBP               £   \n",
       "4  {\"id\":1178460181,\"name\":\"Dawn Johnston\",\"is_re...      USD               $   \n",
       "5  {\"id\":682189804,\"name\":\"Annapolis Chamber Play...      USD               $   \n",
       "\n",
       "   currency_trailing_code current_currency    deadline  disable_communication  \\\n",
       "0                    True              USD  1552539775                  False   \n",
       "1                    True              USD  1504976459                  False   \n",
       "2                    True              USD  1371013395                  False   \n",
       "3                   False              USD  1489425776                  False   \n",
       "4                    True              USD  1357763527                  False   \n",
       "5                    True              USD  1430533546                  False   \n",
       "\n",
       "                 file friends   fx_rate     goal          id is_backing  \\\n",
       "0  Kickstarter040.csv     NaN  1.000000  28000.0  2108505034        NaN   \n",
       "1  Kickstarter040.csv     NaN  1.000000   1000.0   928751314        NaN   \n",
       "2  Kickstarter040.csv     NaN  1.000000  15000.0   928014092        NaN   \n",
       "3  Kickstarter040.csv     NaN  1.308394  10000.0   596091328        NaN   \n",
       "4  Kickstarter040.csv     NaN  1.000000   2800.0   998516049        NaN   \n",
       "5  Kickstarter040.csv     NaN  1.000000   3500.0  1224600291        NaN   \n",
       "\n",
       "   is_starrable is_starred  launched_at  \\\n",
       "0         False        NaN   1548223375   \n",
       "1         False        NaN   1502384459   \n",
       "2         False        NaN   1368421395   \n",
       "3         False        NaN   1484245376   \n",
       "4         False        NaN   1355171527   \n",
       "5         False        NaN   1427941546   \n",
       "\n",
       "                                            location  \\\n",
       "0  {\"id\":2462429,\"name\":\"Novato\",\"slug\":\"novato-c...   \n",
       "1  {\"id\":2400549,\"name\":\"Euless\",\"slug\":\"euless-t...   \n",
       "2  {\"id\":2423474,\"name\":\"Hollywood\",\"slug\":\"holly...   \n",
       "3  {\"id\":475457,\"name\":\"Kaunas\",\"slug\":\"kaunas-ka...   \n",
       "4  {\"id\":2507703,\"name\":\"Traverse City\",\"slug\":\"t...   \n",
       "5  {\"id\":2354877,\"name\":\"Annapolis\",\"slug\":\"annap...   \n",
       "\n",
       "                                                name permissions  \\\n",
       "0                           Babalus Children's Shoes         NaN   \n",
       "1                            The Ofrenda Oracle Deck         NaN   \n",
       "2  Record Electra's Debut Album (Pop, Rock, Class...         NaN   \n",
       "3                 The Mist of Tribunal - A Card Game         NaN   \n",
       "4           Help change the face of Brain Impairment         NaN   \n",
       "5                    Annapolis Chamber Music Project         NaN   \n",
       "\n",
       "                                               photo  pledged  \\\n",
       "0  {\"key\":\"assets/023/667/205/a565fde5382d6b53276...  28645.0   \n",
       "1  {\"key\":\"assets/017/766/989/dd9f18c773a8546d996...   1950.0   \n",
       "2  {\"key\":\"assets/011/433/681/489fd66f7861fefd8c8...  22404.0   \n",
       "3  {\"key\":\"assets/015/091/198/216fbf1bdc3739e7971...    136.0   \n",
       "4  {\"key\":\"assets/011/457/844/37ba63d35fefaba76e9...   2820.0   \n",
       "5  {\"key\":\"assets/011/921/106/c9ad5416f0b588b37b7...   3725.0   \n",
       "\n",
       "                                             profile  \\\n",
       "0  {\"id\":3508024,\"project_id\":3508024,\"state\":\"in...   \n",
       "1  {\"id\":3094785,\"project_id\":3094785,\"state\":\"ac...   \n",
       "2  {\"id\":359847,\"project_id\":359847,\"state\":\"inac...   \n",
       "3  {\"id\":2825329,\"project_id\":2825329,\"state\":\"in...   \n",
       "4  {\"id\":417385,\"project_id\":417385,\"state\":\"inac...   \n",
       "5  {\"id\":1465941,\"project_id\":1465941,\"state\":\"in...   \n",
       "\n",
       "                                             slug  \\\n",
       "0                         babalus-childrens-shoes   \n",
       "1                         the-ofrenda-oracle-deck   \n",
       "2  record-electras-debut-album-pop-rock-classical   \n",
       "3                the-mist-of-tribunal-a-card-game   \n",
       "4        help-change-the-face-of-brain-impairment   \n",
       "5                 annapolis-chamber-music-project   \n",
       "\n",
       "                                          source_url  spotlight  staff_pick  \\\n",
       "0  https://www.kickstarter.com/discover/categorie...      False       False   \n",
       "1  https://www.kickstarter.com/discover/categorie...       True       False   \n",
       "2  https://www.kickstarter.com/discover/categorie...       True       False   \n",
       "3  https://www.kickstarter.com/discover/categorie...      False       False   \n",
       "4  https://www.kickstarter.com/discover/categorie...       True       False   \n",
       "5  https://www.kickstarter.com/discover/categorie...       True       False   \n",
       "\n",
       "        state  state_changed_at  static_usd_rate  \\\n",
       "0        live        1548223375         1.000000   \n",
       "1  successful        1504976459         1.000000   \n",
       "2  successful        1371013395         1.000000   \n",
       "3      failed        1489425776         1.216066   \n",
       "4  successful        1357763527         1.000000   \n",
       "5  successful        1430533546         1.000000   \n",
       "\n",
       "                                                urls   usd_pledged  \\\n",
       "0  {\"web\":{\"project\":\"https://www.kickstarter.com...  28645.000000   \n",
       "1  {\"web\":{\"project\":\"https://www.kickstarter.com...   1950.000000   \n",
       "2  {\"web\":{\"project\":\"https://www.kickstarter.com...  22404.000000   \n",
       "3  {\"web\":{\"project\":\"https://www.kickstarter.com...    165.384934   \n",
       "4  {\"web\":{\"project\":\"https://www.kickstarter.com...   2820.000000   \n",
       "5  {\"web\":{\"project\":\"https://www.kickstarter.com...   3725.000000   \n",
       "\n",
       "        usd_type  \n",
       "0  international  \n",
       "1       domestic  \n",
       "2  international  \n",
       "3       domestic  \n",
       "4       domestic  \n",
       "5       domestic  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display head(5) of \"data_insp\"\n",
    "pd.set_option('display.max_columns', 50)\n",
    "data_insp.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backers_count', 'blurb', 'category', 'converted_pledged_amount',\n",
       "       'country', 'created_at', 'creator', 'currency', 'currency_symbol',\n",
       "       'currency_trailing_code', 'current_currency', 'deadline',\n",
       "       'disable_communication', 'file', 'friends', 'fx_rate', 'goal', 'id',\n",
       "       'is_backing', 'is_starrable', 'is_starred', 'launched_at', 'location',\n",
       "       'name', 'permissions', 'photo', 'pledged', 'profile', 'slug',\n",
       "       'source_url', 'spotlight', 'staff_pick', 'state', 'state_changed_at',\n",
       "       'static_usd_rate', 'urls', 'usd_pledged', 'usd_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display columns of \"data\"\n",
    "data_insp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209222, 38)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with random single csv file\n",
    "data0 = pd.read_csv(\"data/Kickstarter015.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <th>created_at</th>\n",
       "      <th>deadline</th>\n",
       "      <th>fx_rate</th>\n",
       "      <th>goal</th>\n",
       "      <th>id</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>usd_pledged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209222.00</td>\n",
       "      <td>209222.00</td>\n",
       "      <td>2.092220e+05</td>\n",
       "      <td>2.092220e+05</td>\n",
       "      <td>209222.00</td>\n",
       "      <td>2.092220e+05</td>\n",
       "      <td>2.092220e+05</td>\n",
       "      <td>2.092220e+05</td>\n",
       "      <td>209222.00</td>\n",
       "      <td>2.092220e+05</td>\n",
       "      <td>209222.00</td>\n",
       "      <td>209222.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>145.42</td>\n",
       "      <td>12892.90</td>\n",
       "      <td>1.456089e+09</td>\n",
       "      <td>1.463033e+09</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.917604e+04</td>\n",
       "      <td>1.073222e+09</td>\n",
       "      <td>1.460206e+09</td>\n",
       "      <td>18814.03</td>\n",
       "      <td>1.462838e+09</td>\n",
       "      <td>1.01</td>\n",
       "      <td>12892.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>885.97</td>\n",
       "      <td>88894.14</td>\n",
       "      <td>6.339711e+07</td>\n",
       "      <td>6.305618e+07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.179427e+06</td>\n",
       "      <td>6.198051e+08</td>\n",
       "      <td>6.309029e+07</td>\n",
       "      <td>322959.62</td>\n",
       "      <td>6.290421e+07</td>\n",
       "      <td>0.23</td>\n",
       "      <td>88901.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.240366e+09</td>\n",
       "      <td>1.241334e+09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>8.624000e+03</td>\n",
       "      <td>1.240603e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.241334e+09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.00</td>\n",
       "      <td>106.00</td>\n",
       "      <td>1.413317e+09</td>\n",
       "      <td>1.420607e+09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.500000e+03</td>\n",
       "      <td>5.351054e+08</td>\n",
       "      <td>1.417639e+09</td>\n",
       "      <td>110.00</td>\n",
       "      <td>1.420485e+09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>106.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.00</td>\n",
       "      <td>1537.00</td>\n",
       "      <td>1.457895e+09</td>\n",
       "      <td>1.464754e+09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1.074579e+09</td>\n",
       "      <td>1.461924e+09</td>\n",
       "      <td>1556.00</td>\n",
       "      <td>1.464709e+09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1537.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>89.00</td>\n",
       "      <td>6548.00</td>\n",
       "      <td>1.511595e+09</td>\n",
       "      <td>1.519437e+09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>1.609369e+09</td>\n",
       "      <td>1.516694e+09</td>\n",
       "      <td>6887.20</td>\n",
       "      <td>1.519366e+09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6550.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105857.00</td>\n",
       "      <td>8596474.00</td>\n",
       "      <td>1.552527e+09</td>\n",
       "      <td>1.557721e+09</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>2.147476e+09</td>\n",
       "      <td>1.552537e+09</td>\n",
       "      <td>81030744.00</td>\n",
       "      <td>1.552537e+09</td>\n",
       "      <td>1.72</td>\n",
       "      <td>8596474.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       backers_count  converted_pledged_amount    created_at      deadline  \\\n",
       "count      209222.00                 209222.00  2.092220e+05  2.092220e+05   \n",
       "mean          145.42                  12892.90  1.456089e+09  1.463033e+09   \n",
       "std           885.97                  88894.14  6.339711e+07  6.305618e+07   \n",
       "min             0.00                      0.00  1.240366e+09  1.241334e+09   \n",
       "25%             4.00                    106.00  1.413317e+09  1.420607e+09   \n",
       "50%            27.00                   1537.00  1.457895e+09  1.464754e+09   \n",
       "75%            89.00                   6548.00  1.511595e+09  1.519437e+09   \n",
       "max        105857.00                8596474.00  1.552527e+09  1.557721e+09   \n",
       "\n",
       "         fx_rate          goal            id   launched_at      pledged  \\\n",
       "count  209222.00  2.092220e+05  2.092220e+05  2.092220e+05    209222.00   \n",
       "mean        0.99  4.917604e+04  1.073222e+09  1.460206e+09     18814.03   \n",
       "std         0.21  1.179427e+06  6.198051e+08  6.309029e+07    322959.62   \n",
       "min         0.01  1.000000e-02  8.624000e+03  1.240603e+09         0.00   \n",
       "25%         1.00  1.500000e+03  5.351054e+08  1.417639e+09       110.00   \n",
       "50%         1.00  5.000000e+03  1.074579e+09  1.461924e+09      1556.00   \n",
       "75%         1.00  1.500000e+04  1.609369e+09  1.516694e+09      6887.20   \n",
       "max         1.88  1.000000e+08  2.147476e+09  1.552537e+09  81030744.00   \n",
       "\n",
       "       state_changed_at  static_usd_rate  usd_pledged  \n",
       "count      2.092220e+05        209222.00    209222.00  \n",
       "mean       1.462838e+09             1.01     12892.13  \n",
       "std        6.290421e+07             0.23     88901.24  \n",
       "min        1.241334e+09             0.01         0.00  \n",
       "25%        1.420485e+09             1.00       106.00  \n",
       "50%        1.464709e+09             1.00      1537.36  \n",
       "75%        1.519366e+09             1.00      6550.00  \n",
       "max        1.552537e+09             1.72   8596474.58  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe data (summary)\n",
    "data_insp.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209222 entries, 0 to 209221\n",
      "Data columns (total 38 columns):\n",
      "backers_count               209222 non-null int64\n",
      "blurb                       209214 non-null object\n",
      "category                    209222 non-null object\n",
      "converted_pledged_amount    209222 non-null int64\n",
      "country                     209222 non-null object\n",
      "created_at                  209222 non-null int64\n",
      "creator                     209222 non-null object\n",
      "currency                    209222 non-null object\n",
      "currency_symbol             209222 non-null object\n",
      "currency_trailing_code      209222 non-null bool\n",
      "current_currency            209222 non-null object\n",
      "deadline                    209222 non-null int64\n",
      "disable_communication       209222 non-null bool\n",
      "file                        209222 non-null object\n",
      "friends                     300 non-null object\n",
      "fx_rate                     209222 non-null float64\n",
      "goal                        209222 non-null float64\n",
      "id                          209222 non-null int64\n",
      "is_backing                  300 non-null object\n",
      "is_starrable                209222 non-null bool\n",
      "is_starred                  300 non-null object\n",
      "launched_at                 209222 non-null int64\n",
      "location                    208996 non-null object\n",
      "name                        209222 non-null object\n",
      "permissions                 300 non-null object\n",
      "photo                       209222 non-null object\n",
      "pledged                     209222 non-null float64\n",
      "profile                     209222 non-null object\n",
      "slug                        209222 non-null object\n",
      "source_url                  209222 non-null object\n",
      "spotlight                   209222 non-null bool\n",
      "staff_pick                  209222 non-null bool\n",
      "state                       209222 non-null object\n",
      "state_changed_at            209222 non-null int64\n",
      "static_usd_rate             209222 non-null float64\n",
      "urls                        209222 non-null object\n",
      "usd_pledged                 209222 non-null float64\n",
      "usd_type                    208742 non-null object\n",
      "dtypes: bool(5), float64(5), int64(7), object(21)\n",
      "memory usage: 53.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# List datatypes (data.info())\n",
    "data_insp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backers_count                 3246\n",
       "blurb                       180700\n",
       "category                       169\n",
       "converted_pledged_amount     31387\n",
       "country                         22\n",
       "created_at                  182158\n",
       "creator                     208562\n",
       "currency                        14\n",
       "currency_symbol                  6\n",
       "currency_trailing_code           2\n",
       "current_currency                 5\n",
       "deadline                    170854\n",
       "disable_communication            2\n",
       "file                            56\n",
       "friends                          1\n",
       "fx_rate                         67\n",
       "goal                          5110\n",
       "id                          182264\n",
       "is_backing                       1\n",
       "is_starrable                     2\n",
       "is_starred                       2\n",
       "launched_at                 182109\n",
       "location                     15235\n",
       "name                        181680\n",
       "permissions                      1\n",
       "photo                       182263\n",
       "pledged                      44387\n",
       "profile                     182265\n",
       "slug                        182264\n",
       "source_url                     169\n",
       "spotlight                        2\n",
       "staff_pick                       2\n",
       "state                            5\n",
       "state_changed_at            172048\n",
       "static_usd_rate              11195\n",
       "urls                        182554\n",
       "usd_pledged                  79235\n",
       "usd_type                         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List unique entries per column\n",
    "data_insp.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <th>created_at</th>\n",
       "      <th>currency_trailing_code</th>\n",
       "      <th>deadline</th>\n",
       "      <th>disable_communication</th>\n",
       "      <th>fx_rate</th>\n",
       "      <th>goal</th>\n",
       "      <th>id</th>\n",
       "      <th>is_starrable</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>pledged</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>usd_pledged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>backers_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805201</td>\n",
       "      <td>0.025763</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>-0.007194</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.006344</td>\n",
       "      <td>0.031367</td>\n",
       "      <td>0.251022</td>\n",
       "      <td>0.123834</td>\n",
       "      <td>0.157586</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.804528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <td>0.805201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>0.036793</td>\n",
       "      <td>-0.005632</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.006009</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.311144</td>\n",
       "      <td>0.108999</td>\n",
       "      <td>0.143488</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>0.999861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <td>0.025763</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>-0.005590</td>\n",
       "      <td>-0.067095</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>-0.003722</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.983917</td>\n",
       "      <td>0.027735</td>\n",
       "      <td>-0.038476</td>\n",
       "      <td>-0.044145</td>\n",
       "      <td>0.983657</td>\n",
       "      <td>-0.103533</td>\n",
       "      <td>0.031305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_trailing_code</th>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.159145</td>\n",
       "      <td>-0.003072</td>\n",
       "      <td>-0.530710</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>-0.029686</td>\n",
       "      <td>-0.159141</td>\n",
       "      <td>-0.014496</td>\n",
       "      <td>0.026252</td>\n",
       "      <td>0.008887</td>\n",
       "      <td>-0.159209</td>\n",
       "      <td>-0.588899</td>\n",
       "      <td>0.010939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deadline</th>\n",
       "      <td>0.031456</td>\n",
       "      <td>0.036793</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>-0.159145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007501</td>\n",
       "      <td>-0.066400</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>-0.002373</td>\n",
       "      <td>0.265997</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.029352</td>\n",
       "      <td>-0.036473</td>\n",
       "      <td>-0.035992</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>-0.104718</td>\n",
       "      <td>0.036689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disable_communication</th>\n",
       "      <td>-0.007194</td>\n",
       "      <td>-0.005632</td>\n",
       "      <td>-0.005590</td>\n",
       "      <td>-0.003072</td>\n",
       "      <td>-0.007501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006571</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>-0.007664</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.061833</td>\n",
       "      <td>-0.021032</td>\n",
       "      <td>-0.009238</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>-0.005637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fx_rate</th>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>-0.067095</td>\n",
       "      <td>-0.530710</td>\n",
       "      <td>-0.066400</td>\n",
       "      <td>-0.006571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034576</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>-0.009580</td>\n",
       "      <td>-0.065782</td>\n",
       "      <td>-0.086680</td>\n",
       "      <td>0.019898</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>-0.066377</td>\n",
       "      <td>0.962465</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal</th>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>-0.034576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.127876</td>\n",
       "      <td>-0.033962</td>\n",
       "      <td>-0.004262</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>-0.031928</td>\n",
       "      <td>0.010240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.003722</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>-0.002373</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>-0.003055</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>-0.002404</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_starrable</th>\n",
       "      <td>-0.006344</td>\n",
       "      <td>-0.006009</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>-0.029686</td>\n",
       "      <td>0.265997</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>-0.009580</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264429</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>-0.207692</td>\n",
       "      <td>-0.019257</td>\n",
       "      <td>0.257530</td>\n",
       "      <td>-0.035726</td>\n",
       "      <td>-0.006544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launched_at</th>\n",
       "      <td>0.031367</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.983917</td>\n",
       "      <td>-0.159141</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>-0.007664</td>\n",
       "      <td>-0.065782</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>0.264429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029154</td>\n",
       "      <td>-0.033671</td>\n",
       "      <td>-0.035543</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>-0.104067</td>\n",
       "      <td>0.036333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pledged</th>\n",
       "      <td>0.251022</td>\n",
       "      <td>0.311144</td>\n",
       "      <td>0.027735</td>\n",
       "      <td>-0.014496</td>\n",
       "      <td>0.029352</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.086680</td>\n",
       "      <td>0.127876</td>\n",
       "      <td>-0.003055</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>0.029154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043675</td>\n",
       "      <td>0.061921</td>\n",
       "      <td>0.029506</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>0.311621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spotlight</th>\n",
       "      <td>0.123834</td>\n",
       "      <td>0.108999</td>\n",
       "      <td>-0.038476</td>\n",
       "      <td>0.026252</td>\n",
       "      <td>-0.036473</td>\n",
       "      <td>-0.061833</td>\n",
       "      <td>0.019898</td>\n",
       "      <td>-0.033962</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>-0.207692</td>\n",
       "      <td>-0.033671</td>\n",
       "      <td>0.043675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>-0.033049</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.109219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staff_pick</th>\n",
       "      <td>0.157586</td>\n",
       "      <td>0.143488</td>\n",
       "      <td>-0.044145</td>\n",
       "      <td>0.008887</td>\n",
       "      <td>-0.035992</td>\n",
       "      <td>-0.021032</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>-0.004262</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>-0.019257</td>\n",
       "      <td>-0.035543</td>\n",
       "      <td>0.061921</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035426</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.143497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_changed_at</th>\n",
       "      <td>0.031798</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.983657</td>\n",
       "      <td>-0.159209</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>-0.009238</td>\n",
       "      <td>-0.066377</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>-0.002404</td>\n",
       "      <td>0.257530</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>0.029506</td>\n",
       "      <td>-0.033049</td>\n",
       "      <td>-0.035426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.104586</td>\n",
       "      <td>0.037010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>static_usd_rate</th>\n",
       "      <td>-0.000877</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.103533</td>\n",
       "      <td>-0.588899</td>\n",
       "      <td>-0.104718</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>0.962465</td>\n",
       "      <td>-0.031928</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.035726</td>\n",
       "      <td>-0.104067</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>-0.104586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_pledged</th>\n",
       "      <td>0.804528</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>0.036689</td>\n",
       "      <td>-0.005637</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>-0.006544</td>\n",
       "      <td>0.036333</td>\n",
       "      <td>0.311621</td>\n",
       "      <td>0.109219</td>\n",
       "      <td>0.143497</td>\n",
       "      <td>0.037010</td>\n",
       "      <td>-0.002541</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          backers_count  converted_pledged_amount  created_at  \\\n",
       "backers_count                  1.000000                  0.805201    0.025763   \n",
       "converted_pledged_amount       0.805201                  1.000000    0.031417   \n",
       "created_at                     0.025763                  0.031417    1.000000   \n",
       "currency_trailing_code         0.010566                  0.011129   -0.163048   \n",
       "deadline                       0.031456                  0.036793    0.983713   \n",
       "disable_communication         -0.007194                 -0.005632   -0.005590   \n",
       "fx_rate                        0.003313                  0.001674   -0.067095   \n",
       "goal                           0.010019                  0.010144    0.003976   \n",
       "id                            -0.002635                 -0.001675   -0.003722   \n",
       "is_starrable                  -0.006344                 -0.006009    0.259400   \n",
       "launched_at                    0.031367                  0.036437    0.983917   \n",
       "pledged                        0.251022                  0.311144    0.027735   \n",
       "spotlight                      0.123834                  0.108999   -0.038476   \n",
       "staff_pick                     0.157586                  0.143488   -0.044145   \n",
       "state_changed_at               0.031798                  0.037109    0.983657   \n",
       "static_usd_rate               -0.000877                 -0.002628   -0.103533   \n",
       "usd_pledged                    0.804528                  0.999861    0.031305   \n",
       "\n",
       "                          currency_trailing_code  deadline  \\\n",
       "backers_count                           0.010566  0.031456   \n",
       "converted_pledged_amount                0.011129  0.036793   \n",
       "created_at                             -0.163048  0.983713   \n",
       "currency_trailing_code                  1.000000 -0.159145   \n",
       "deadline                               -0.159145  1.000000   \n",
       "disable_communication                  -0.003072 -0.007501   \n",
       "fx_rate                                -0.530710 -0.066400   \n",
       "goal                                   -0.001589  0.004798   \n",
       "id                                      0.003703 -0.002373   \n",
       "is_starrable                           -0.029686  0.265997   \n",
       "launched_at                            -0.159141  0.999869   \n",
       "pledged                                -0.014496  0.029352   \n",
       "spotlight                               0.026252 -0.036473   \n",
       "staff_pick                              0.008887 -0.035992   \n",
       "state_changed_at                       -0.159209  0.999926   \n",
       "static_usd_rate                        -0.588899 -0.104718   \n",
       "usd_pledged                             0.010939  0.036689   \n",
       "\n",
       "                          disable_communication   fx_rate      goal        id  \\\n",
       "backers_count                         -0.007194  0.003313  0.010019 -0.002635   \n",
       "converted_pledged_amount              -0.005632  0.001674  0.010144 -0.001675   \n",
       "created_at                            -0.005590 -0.067095  0.003976 -0.003722   \n",
       "currency_trailing_code                -0.003072 -0.530710 -0.001589  0.003703   \n",
       "deadline                              -0.007501 -0.066400  0.004798 -0.002373   \n",
       "disable_communication                  1.000000 -0.006571  0.008566  0.003209   \n",
       "fx_rate                               -0.006571  1.000000 -0.034576 -0.002264   \n",
       "goal                                   0.008566 -0.034576  1.000000  0.001609   \n",
       "id                                     0.003209 -0.002264  0.001609  1.000000   \n",
       "is_starrable                          -0.010032 -0.009580 -0.000269  0.001471   \n",
       "launched_at                           -0.007664 -0.065782  0.004305 -0.002432   \n",
       "pledged                               -0.002400 -0.086680  0.127876 -0.003055   \n",
       "spotlight                             -0.061833  0.019898 -0.033962 -0.000518   \n",
       "staff_pick                            -0.021032 -0.000702 -0.004262  0.003184   \n",
       "state_changed_at                      -0.009238 -0.066377  0.004632 -0.002404   \n",
       "static_usd_rate                       -0.003848  0.962465 -0.031928 -0.002388   \n",
       "usd_pledged                           -0.005637  0.001465  0.010240 -0.001697   \n",
       "\n",
       "                          is_starrable  launched_at   pledged  spotlight  \\\n",
       "backers_count                -0.006344     0.031367  0.251022   0.123834   \n",
       "converted_pledged_amount     -0.006009     0.036437  0.311144   0.108999   \n",
       "created_at                    0.259400     0.983917  0.027735  -0.038476   \n",
       "currency_trailing_code       -0.029686    -0.159141 -0.014496   0.026252   \n",
       "deadline                      0.265997     0.999869  0.029352  -0.036473   \n",
       "disable_communication        -0.010032    -0.007664 -0.002400  -0.061833   \n",
       "fx_rate                      -0.009580    -0.065782 -0.086680   0.019898   \n",
       "goal                         -0.000269     0.004305  0.127876  -0.033962   \n",
       "id                            0.001471    -0.002432 -0.003055  -0.000518   \n",
       "is_starrable                  1.000000     0.264429 -0.002045  -0.207692   \n",
       "launched_at                   0.264429     1.000000  0.029154  -0.033671   \n",
       "pledged                      -0.002045     0.029154  1.000000   0.043675   \n",
       "spotlight                    -0.207692    -0.033671  0.043675   1.000000   \n",
       "staff_pick                   -0.019257    -0.035543  0.061921   0.245951   \n",
       "state_changed_at              0.257530     0.999835  0.029506  -0.033049   \n",
       "static_usd_rate              -0.035726    -0.104067 -0.081775   0.016730   \n",
       "usd_pledged                  -0.006544     0.036333  0.311621   0.109219   \n",
       "\n",
       "                          staff_pick  state_changed_at  static_usd_rate  \\\n",
       "backers_count               0.157586          0.031798        -0.000877   \n",
       "converted_pledged_amount    0.143488          0.037109        -0.002628   \n",
       "created_at                 -0.044145          0.983657        -0.103533   \n",
       "currency_trailing_code      0.008887         -0.159209        -0.588899   \n",
       "deadline                   -0.035992          0.999926        -0.104718   \n",
       "disable_communication      -0.021032         -0.009238        -0.003848   \n",
       "fx_rate                    -0.000702         -0.066377         0.962465   \n",
       "goal                       -0.004262          0.004632        -0.031928   \n",
       "id                          0.003184         -0.002404        -0.002388   \n",
       "is_starrable               -0.019257          0.257530        -0.035726   \n",
       "launched_at                -0.035543          0.999835        -0.104067   \n",
       "pledged                     0.061921          0.029506        -0.081775   \n",
       "spotlight                   0.245951         -0.033049         0.016730   \n",
       "staff_pick                  1.000000         -0.035426         0.000968   \n",
       "state_changed_at           -0.035426          1.000000        -0.104586   \n",
       "static_usd_rate             0.000968         -0.104586         1.000000   \n",
       "usd_pledged                 0.143497          0.037010        -0.002541   \n",
       "\n",
       "                          usd_pledged  \n",
       "backers_count                0.804528  \n",
       "converted_pledged_amount     0.999861  \n",
       "created_at                   0.031305  \n",
       "currency_trailing_code       0.010939  \n",
       "deadline                     0.036689  \n",
       "disable_communication       -0.005637  \n",
       "fx_rate                      0.001465  \n",
       "goal                         0.010240  \n",
       "id                          -0.001697  \n",
       "is_starrable                -0.006544  \n",
       "launched_at                  0.036333  \n",
       "pledged                      0.311621  \n",
       "spotlight                    0.109219  \n",
       "staff_pick                   0.143497  \n",
       "state_changed_at             0.037010  \n",
       "static_usd_rate             -0.002541  \n",
       "usd_pledged                  1.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List correlation values\n",
    "data_insp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permissions    208922\n",
      "is_starred     208922\n",
      "is_backing     208922\n",
      "friends        208922\n",
      "usd_type          480\n",
      "location          226\n",
      "blurb               8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List missing values\n",
    "\n",
    "def count_missing(data):\n",
    "    null_cols = data_insp.columns[data.isnull().any(axis=0)]\n",
    "    X_null = data[null_cols].isnull().sum()\n",
    "    X_null = X_null.sort_values(ascending=False)\n",
    "    print(X_null)\n",
    "    \n",
    "count_missing(data_insp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- High correlation:\n",
    "  - usd_pledged and converted_pledged_amount (drop one)\n",
    "  - backers_count and converted_pledged_amount (create avg_backing, then drop backers_count)\n",
    "  - Only 182.264 unique ID's, so projects can be listed multiple times (depending on what? changing state?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling\n",
    "Purpose: Construct a clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initial drop of unnecessary columns\n",
    "data.drop([\"blurb\", 'currency_symbol', 'file', 'friends', 'fx_rate', 'is_backing', 'is_starred', 'location', 'name', 'permissions', 'photo', 'pledged', 'slug', \"urls\", 'usd_pledged'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Extract category_sub from \"category\"\n",
    "data[\"category_sub\"] = [data.category[i].split('\"')[5] for i in range(len(data.category))]\n",
    "data[\"category_sub\"] = data[\"category_sub\"].str.replace(\"%20\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Extract category from \"source_url\"\n",
    "data[\"category\"] = [data.source_url[i].split(\"/\")[5] for i in range(len(data.source_url))]\n",
    "data[\"category\"] = data[\"category\"].str.replace(\"%20\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Extract id of \"creator\"\n",
    "data[\"creator_id\"] = [data.creator[i].split('\"')[2][1:-1] for i in range(len(data.creator))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Extract project_id of \"profile\"\n",
    "data[\"project_id\"] = [data.profile[i].split('\"')[4][1:-1] for i in range(len(data.profile))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Extract profile_state of \"profile\"\n",
    "data[\"profile_state\"] = [data.profile[i].split('\"')[7] for i in range(len(data.profile))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Extract profile_state_changed_at of \"profile\"\n",
    "data[\"profile_state_changed_at\"] = [data.profile[i].split('\"')[10][1:-1] for i in range(len(data.profile))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display content of newly created columns\n",
    "#data.creator_id.value_counts()\n",
    "#data.project_id.value_counts()\n",
    "#data.profile_state.value_counts()\n",
    "#data.profile_state_changed_at.value_counts()\n",
    "#data[data.creator_id == \"1704592942\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Extract city from \"location\" column (OPTIONAL, might not be needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Drop rows with non-numerical values (only if few!)\n",
    "#data = data[pd.to_numeric(data['column_with_nonnum'], errors='coerce').notnull()]\n",
    "#data['column_with_nonnum'] = data['column_with_nonnum'].astype('int')\n",
    "#data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform created_at from timestamp to datetime\n",
    "data.created_at = pd.to_datetime(data.created_at, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform deadline from timestamp to datetime\n",
    "data.deadline = pd.to_datetime(data.deadline, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform launched_at from timestamp to datetime\n",
    "data.launched_at = pd.to_datetime(data.launched_at, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform state_changed_at from timestamp to datetime\n",
    "data.state_changed_at = pd.to_datetime(data.state_changed_at, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform profile_state_changed_at from timestamp to datetime\n",
    "data.profile_state_changed_at = pd.to_datetime(data.profile_state_changed_at, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convert currency_trailing_code to 1/0\n",
    "data.currency_trailing_code.replace([True, False], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convert disable_communication to 1/0\n",
    "data.disable_communication.replace([True, False], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convert is_starrable to 1/0\n",
    "data.is_starrable.replace([True, False], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convert spotlight to 1/0\n",
    "data.spotlight.replace([True, False], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convert staff_pick to 1/0\n",
    "data.staff_pick.replace([True, False], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convert profile_state to 1/0\n",
    "data.profile_state.replace([\"active\", \"inactive\"], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Convert NaN in usd_type to \"not_USD\"\n",
    "data.usd_type.replace([\"NaN\"], [\"not_USD\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Creating list for categorical predictors/features (used in \"Scaling with Preprocessing Pipeline\") \n",
    "#cat_features = list(data.columns[data.dtypes==object])\n",
    "#cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Creating list for numerical predictors/features (removing target column, used in \"Scaling with Preprocessing Pipeline\")\n",
    "#num_features = list(data.columns[data.dtypes!=object])\n",
    "#num_features.remove('TARGET')\n",
    "#num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Apply further cleaning\n",
    "#code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Post-cleaning drop of unnecessary columns\n",
    "data.drop([\"creator\", \"profile\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209222, 26)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209222 entries, 0 to 209221\n",
      "Data columns (total 26 columns):\n",
      "backers_count               209222 non-null int64\n",
      "category                    209222 non-null object\n",
      "converted_pledged_amount    209222 non-null int64\n",
      "country                     209222 non-null object\n",
      "created_at                  209222 non-null datetime64[ns]\n",
      "currency                    209222 non-null object\n",
      "currency_trailing_code      209222 non-null int64\n",
      "current_currency            209222 non-null object\n",
      "deadline                    209222 non-null datetime64[ns]\n",
      "disable_communication       209222 non-null int64\n",
      "goal                        209222 non-null float64\n",
      "id                          209222 non-null int64\n",
      "is_starrable                209222 non-null int64\n",
      "launched_at                 209222 non-null datetime64[ns]\n",
      "source_url                  209222 non-null object\n",
      "spotlight                   209222 non-null int64\n",
      "staff_pick                  209222 non-null int64\n",
      "state                       209222 non-null object\n",
      "state_changed_at            209222 non-null datetime64[ns]\n",
      "static_usd_rate             209222 non-null float64\n",
      "usd_type                    208742 non-null object\n",
      "category_sub                209222 non-null object\n",
      "creator_id                  209222 non-null object\n",
      "project_id                  209222 non-null object\n",
      "profile_state               209222 non-null int64\n",
      "profile_state_changed_at    209222 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](5), float64(2), int64(9), object(10)\n",
      "memory usage: 41.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Purpose: Form hypotheses about your defined problem by visually analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Clean data set for exploration\n",
    "data_clean = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Drop features for exploration\n",
    "data_clean = data_clean.drop([\"column1\", \"column2\", \"column3\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Separate continuous vs. categorical variables\n",
    "data_cat_col = ['condition', 'date', 'date_month', 'date_year', 'grade','zipcode', 'view']\n",
    "data_cont_col = [el for el in data_clean.columns if el not in data_cat_col]\n",
    "data_cont = data_clean[data_cont_col]\n",
    "data_cat = data_clean[data_cat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Look at data skew\n",
    "data_clean.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot correlation heatmap for continuous variables\n",
    "#Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(data_cont.corr(), dtype=np.bool))\n",
    "\n",
    "#Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "#Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "#Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(data_cont.corr(), mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt=\".1g\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot factorplot\n",
    "sns.factorplot(\"sex\", col='education_level', data=data_clean, hue='income', kind=\"count\", col_wrap=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot jointplot (1 feature)\n",
    "sns.jointplot(x='feature', y='target', data=data_clean, kind='hex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot lmplot (3 features)\n",
    "sns.lmplot(y='target', x='feature_1', data=loans, hue='feature_2', \\\n",
    "           col='feature_3 (plotted as separate graphs)', palette='Set1', scatter_kws={'alpha':0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot all variables as pairplot\n",
    "sns.pairplot(data_clean);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot selection of variables as pairplot\n",
    "sns.pairplot(data_clean, kind=\"reg\", vars=[\"price\", \"bedrooms\", \"bathrooms\", \"sqft_lot\"], \n",
    "             plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.1}});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot FacetGrid\n",
    "g = sns.FacetGrid(data_clean,\n",
    "                  col='view',\n",
    "                  row='bedrooms',\n",
    "                  hue='waterfront',\n",
    "                  palette='Set2')\n",
    "g = (g.map(plt.scatter, 'sqft_living', 'price').add_legend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot continuous variables\n",
    "plt.hist(data_clean.price, bins = 25);\n",
    "plt.hist(np.log(data_clean.price), bins = 25);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot skewed features (OPTIMIZE - HOW?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot categorical variables\n",
    "sns.stripplot(x=data_clean.condition.values, y = data_clean.price.values, \n",
    "              jitter=0.1, alpha=0.5);\n",
    "\n",
    "sns.stripplot(x=data_clean.grade.values, y = data_clean.price.values,\n",
    "              jitter=0.1, alpha=0.5);\n",
    "\n",
    "sns.stripplot(x=data_clean.zipcode.values, y = data_clean.price.values,\n",
    "              jitter=0.1, alpha=0.5);\n",
    "\n",
    "sns.pointplot(x = data_clean.zipcode.values, y = data_clean.price.values,\n",
    "              order = data_clean.groupby(\"zipcode\")[\"price\"].mean().sort_values().index);\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Purpose: Select important features and construct more meaningful ones using the raw data that you have\n",
    "\n",
    "To-Do's:\n",
    "- Start with brainstorming session to determine which features could be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline # Same, but with the latter it is not necessary to name estimator and transformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create 1/0 target feature for success\n",
    "data[\"success\"] = data[\"state\"] = \"successful\" # Adapt value\n",
    "data.new_column.replace([True, False], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create avg backing feature (converted_pledged_amount / backers_count)\n",
    "data[\"backing_avg\"] = data[\"converted_pledged_amount\"] / data[\"backers_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create log feature from continuous variable\n",
    "data[\"new_column\"] = [math.log(el) for el in data[\"old_column\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fill column to represent the max from two columns\n",
    "data[\"column1\"] = data[[\"column1\",\"column2\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop features\n",
    "data = data.drop([\"converted_pledged_amount\", \"state\", \"column3\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with manual code (alt. to pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Overwrite original data with generic values (mean/median)\n",
    "imp = Imputer(strategy='median')\n",
    "data = imp.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Overwrite original data with generic values, after train/test split (mean/median)\n",
    "X_train = train.fillna(train.mean())\n",
    "X_test = test.fillna(train.mean())\n",
    "\n",
    "# Features for feature importances\n",
    "features = list(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical features (manual, alt. to pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform highly skewed features (log-transform)\n",
    "skewed = [\"skewed_feature1\", \"skewed_feature2\"]\n",
    "data[skewed] = data[skewed].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize numerical features (MinMaxScaler: rescales the data set such that all feature values are in the range [0, 1])\n",
    "scaler = MinMaxScaler()\n",
    "numerical = [\"numerical_feature1 (e.g. age)\", \"numerical_feature2\"]\n",
    "data[numerical] = scaler.fit_transform(data[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize numerical features (StandardScaler: removes the mean and scales the data to unit variance)\n",
    "scaler = StandardScaler()\n",
    "numerical = [\"numerical_feature1 (e.g. age)\", \"numerical_feature2\"]\n",
    "data[numerical] = scaler.fit(data[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize features (z-Score, not used in final model)\n",
    "#Create new df\n",
    "data_norm = data.copy(deep=True)\n",
    "#drop columns\n",
    "data_norm.drop(['yr_built', 'yr_renovated', 'yr_since_built'],\n",
    "               axis=1,\n",
    "               inplace=True)\n",
    "#z normalize variables\n",
    "data_norm.loc[:, [\n",
    "    'date', 'bedrooms', 'bathrooms', 'waterfront', 'price_log', 'sqft_lot',\n",
    "    'sqft_above', 'sqft_basement', 'floors', 'lat', 'long', 'sqft_living15',\n",
    "    'sqft_lot15', 'yr_since_last_renovated'\n",
    "]] = data.loc[:, [\n",
    "    'date', 'bedrooms', 'bathrooms', 'waterfront', 'price_log', 'sqft_lot',\n",
    "    'sqft_above', 'sqft_basement', 'floors', 'lat', 'long', 'sqft_living15',\n",
    "    'sqft_lot15', 'yr_since_last_renovated'\n",
    "]].apply(zscore)\n",
    "#add intercept column\n",
    "data_norm['intercept'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummies for categorical features (manual, alt. to pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# One-hot encode categorical (non-numeric) features (OPTIMIZE - FIND GOOD METHOD)\n",
    "\n",
    "# Version 1\n",
    "vec = DictVectorizer(sparse=False, dtype=int)\n",
    "vec.fit_transform(data)\n",
    "\n",
    "\n",
    "# Version 2\n",
    "features = pd.get_dummies(features_raw)\n",
    "\n",
    "# TODO: Encode the 'income_raw' data to numerical values\n",
    "income = income_raw.apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features.columns)\n",
    "print (\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# Uncomment the following line to see the encoded feature names \n",
    "# print encoded\n",
    "# Left uncommented due to output size\n",
    "\n",
    "\n",
    "# Version 3\n",
    "cat = data.filter([\"condition\", \n",
    "                   \"grade\", \n",
    "                   \"zipcode\", \"view\"], axis=1).astype(\"category\")\n",
    "data_dum = pd.DataFrame()\n",
    "data_dum_i = pd.DataFrame()\n",
    "for i in cat:\n",
    "    data_dum_i = pd.get_dummies(cat[i], prefix=i, drop_first=True)\n",
    "    data_dum = pd.concat([data_dum, data_dum_i], axis=1)\n",
    "data_without_dum = data\n",
    "data = pd.concat([data, data_dum], axis=1)\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# data_dum = pd.get_dummies(data, columns=[\"condition\", \"grade\", \"zipcode\"], prefix=[\"condition\", \"grade\",\"zipcode\"])\n",
    "# data_wo_dum = data\n",
    "# data_new = pd.concat([data, data_dum], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define predictors and target variable\n",
    "X = data.drop([\"target\", \"optional_column1\"], axis=1)\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=False) # Use stratify=Y if labels are inbalanced (e.g. most wines are 5 or 6; check with value_counts()!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier (to establish baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dummy classifier (requires train/test split)\n",
    "dum_clf = DummyClassifier(strategy= 'most_frequent').fit(X_train,y_train)\n",
    "y_pred_dum_clf = dum_clf.predict(X_test)\n",
    "\n",
    "#Distribution of y test\n",
    "print('y actual : \\n' +  str(y_test.value_counts()))\n",
    "\n",
    "#Distribution of y predicted\n",
    "print('y predicted : \\n' + str(pd.Series(y_pred_dum_clf).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with Pipeline\n",
    "Building a pipeline always follows the same syntax. In our case we create one pipeline for our numerical features and one for our categorical features. In the end both are combined into one pipeline called \"preprocessor\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for imputing and scaling numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Pipeline using Pipeline\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer_num', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Complete pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Pipeline using make_pipeline (To-Do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for imputing, scaling and fitting to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "model = make_pipeline(Imputer(strategy='mean'),\n",
    "                      PolynomialFeatures(degree=2),\n",
    "                      LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit model and test (is the predict code correct?)\n",
    "model.fit(X_train, y_train)  # X with missing values, from above\n",
    "print(y_train)\n",
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling\n",
    "Purpose: Train machine learning models (supervised learning), evaluate their performance and use them to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import make_scorer, fbeta_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Display top features\n",
    "fi = pd.DataFrame({'feature': list(X_train.columns),\n",
    "                   'importance': tree.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "fi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Train a supervised learning model that has 'feature_importances_'\n",
    "model = AdaBoostClassifier().fit(X_train,y_train)\n",
    "\n",
    "# TODO: Extract the feature importances\n",
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Report scores from the final model using both versions of data\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression (R) and Classification (C) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression (R and C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Linear regression with statsmodels sm.OLS\n",
    "X_train = sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Linear regression with sklearn LinearRegression()\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "#plt.scatter(y_test, y_pred)\n",
    "#plt.xlabel('Y Test')\n",
    "#plt.ylabel('Predicted Y')\n",
    "#print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "#print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "#print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "#print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (R and C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Logistic regression (manual)\n",
    "logr = LogisticRegression().fit(X_train,y_train)\n",
    "y_pred = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Logistic regression (using pipeline)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Logistic regression (using pipeline, making predictions using cross validation and probabilities)\n",
    "y_train_predicted = cross_val_predict(pipeline, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Logistic regression (using pipeline, printing results)\n",
    "print('Cross validation scores:')\n",
    "print('-------------------------')\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_train_predicted)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_train_predicted)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_train_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso (where?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#1.2 Lasso with X, y values from #1.1 (0.51) - not used \n",
    "#from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "#import matplotlib\n",
    "\n",
    "#lasso = LassoCV()\n",
    "#lasso.fit(X, y)\n",
    "#print(\"Best alpha using built-in LassoCV: %f\" % lasso.alpha_)\n",
    "#print(\"Best score using built-in LassoCV: %f\" %lasso.score(X,y))\n",
    "#coef = pd.Series(lasso.coef_, index = X.columns)\n",
    "\n",
    "#print(\"Lasso picked \" \n",
    "#      + str(sum(coef != 0)) \n",
    "#      + \" variables and eliminated the other \" \n",
    "#      +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "#imp_coef = coef.sort_values()\n",
    "#matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "#imp_coef.plot(kind = \"barh\")\n",
    "#plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees (R and C)\n",
    "- Real world application: Decision Trees and, in general, CART (Classification and Regression Trees) are often used in financial analysis. A concrete example of it is: for predicting which stocks to buy based on past peformance. Reference\n",
    "- Strengths:\n",
    "  - Able to handle categorical and numerical data.\n",
    "  - Doesn't require much data pre-processing, and can handle data which hasn't been normalized, or encoded for Machine Learning Suitability.\n",
    "  - Simple to understand and interpret.\n",
    "- Weaknesses:\n",
    "  - Complex Decision Trees do not generalize well to the data and can result in overfitting.\n",
    "  - Unstable, as small variations in the data can result in a different decision tree. Hence they are usually used in an ensemble (like Random Forests) to build robustness.\n",
    "  - Can create biased trees if some classes dominate.\n",
    "- Candidacy: Since a decision tree can handle both numerical and categorical data, it's a good candidate for our case (although, the pre-processing steps might already mitigate whatever advantage we would have had). It's also easy to interpret, so we will know what happens under the hood to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_train_pred = dt_clf.predict(X_train)\n",
    "y_train_proba = dt_clf.predict_proba(X_train)\n",
    "\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "y_pred_proba = dt_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,\n",
    "                              random_state=random_state,\n",
    "                              max_depth=5\n",
    "                              max_features=\"sqrt\",\n",
    "                              n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit on training data\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Training predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Testing predictions (to determine performance)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (C)\n",
    "- Real world application: Example of a real world use of SVMs include image classification and image segmentation. For example: Face detection in an image. Reference\n",
    "- Strenghs:\n",
    "  - Effective in high dimensional spaces, or when there are a lot of features.\n",
    "  - Kernel functions can be used to adapt to different cases, and can be completely customized if needed. Thus SVMs are versatile.\n",
    "- Weaknesses:\n",
    "  - Doesn't perform well with large datasets.\n",
    "  - Doesn't directly provide probability estimates.\n",
    "- Candidacy: SVMs were chosen because of their effectiveness given high dimensionality. After incorporating dummy variables, we have more than 100 features in our dataset, so SVMs should be a classifier that works regardless of that. Also, our dataset is not that large to be a deterrent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Pipeline: Find optimal C with Cross-Validation and then Kernel SVC\n",
    "pca = RandomizedPCA(n_components=150, whiten=True, random_state=random_state) # Principal component analysis (PCA) using randomized SVD\n",
    "svc_pre = SVC(kernel='rbf', class_weight='balanced')\n",
    "svc_clf = make_pipeline(pca, svc_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "svc_clf = SVC(kernel=\"linear\", C=1E10) # low C = soft margin, including many values; high C = hard fit\n",
    "svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Kernel SVC (radial basis function)\n",
    "svc_clf = SVC(kernel='rbf', C=1E6)\n",
    "svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Tune model with GridSearchCV (find optimal C)\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]} # Others: kernel, degree (only for poly)\n",
    "grid = GridSearchCV(svc_clf, param_grid)\n",
    "\n",
    "%time grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Try out different kernels\n",
    "kernels = [‘linear’, ‘rbf’, ‘poly’]\n",
    "for kernel in kernels:\n",
    "    svc = svm.SVC(kernel=kernel).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict labels for test data\n",
    "svc_clf_est = grid.best_estimator_\n",
    "y_pred = svc_clf_est.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compare two models\n",
    "model1 = LogisticRegression(random_state=random_state)\n",
    "model2 = DecisionTreeClassifier(random_state=random_state)\n",
    "\n",
    "v_clf = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
    "v_clf.fit(X_train,y_train)\n",
    "v_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Averages three models\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1=model1.predict_proba(X_test)\n",
    "pred2=model2.predict_proba(X_test)\n",
    "pred3=model3.predict_proba(X_test)\n",
    "\n",
    "y_pred=(pred1+pred2+pred3)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Averages three weighted models\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1=model1.predict_proba(X_test)\n",
    "pred2=model2.predict_proba(X_test)\n",
    "pred3=model3.predict_proba(X_test)\n",
    "\n",
    "y_pred=(pred1\\*0.3+pred2\\*0.3+pred3\\*0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define function for stacking\n",
    "def Stacking(model,train,y,test,n_fold):\n",
    "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    test_pred=np.empty((test.shape[0],1),float)\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "  \n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        train_pred=np.append(train_pred,model.predict(x_val))\n",
    "        test_pred=np.append(test_pred,model.predict(test))\n",
    "    return test_pred.reshape(-1,1),train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Call function\n",
    "Stacking(rf_clf, X_train, y_train, X_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "- Real world application: Ensemble methods are used extensively in Kaggle competitions, usually in image detection. A real world example of Adaboost is object detection in image, ex: identifying players during a game of basketball. Reference\n",
    "- Strengths:\n",
    "  - Ensemble methods, including Adaboost are more robust than single estimators, have improved generalizability.\n",
    "  - Simple models can be combined to build a complex model, which is computationally fast.\n",
    "- Weaknesses:\n",
    "  - If we have a biased underlying classifier, it will lead to a biased boosted model.\n",
    "- Candidacy: Ensemble methods are considered to be high quality classifiers, and adaboost is the one of most popular boosting algorithms. We also have a class imbalance in our dataset, which boosting might be robust to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Find good application guideline (reference: notebooks/hh-2020-ds1-Ensemble-Methods-2/2_Adaboost_Codealong.ipynb)\n",
    "clf_ada = AdaBoostClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Determine best parameters with GridSearch\n",
    "cv_params = {'max_depth': [1,2,3,4,5,6], 'min_child_weight': [1,2,3,4]}    # parameters to be tries in the grid search\n",
    "fix_params = {'learning_rate': 0.1, 'n_estimators': 100, 'objective': 'binary:logistic'}   #other parameters, fixed for the moment \n",
    "csv = GridSearchCV(XGBClassifier(**fix_params), cv_params, scoring = 'f1', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit model and print best parameters\n",
    "csv.fit(X_train, y_train)\n",
    "csv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create model with best parameters\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1, max_depth=4, min_child_weight=3)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict values\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Optimization (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit optimized RandomForestClassifier\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "# Create the random search model\n",
    "rs_rf_clf = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=random_state)\n",
    "\n",
    "# Fit \n",
    "rs_rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display best parameters\n",
    "rs_rf_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Use best model for predictions\n",
    "best_model = rs.best_estimator_\n",
    "\n",
    "y_train_pred = best_model.predict(train)\n",
    "y_train_proba = best_model.predict_proba(train)[:, 1]\n",
    "\n",
    "y_test_pred = best_model.predict(test)\n",
    "y_test_proba = best_model.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Predicting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define function for train_predict\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm/classifier to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size],y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples\n",
    "    results['acc_train'] = accuracy_score(y_train[:300],predictions_train)\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples\n",
    "    results['f_train'] = fbeta_score(y_train[:300],predictions_train,0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test,predictions_test,0.5)\n",
    "       \n",
    "    # Success\n",
    "    print (\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set classifiers (if applicable)\n",
    "clf_A = DecisionTreeClassifier(random_state=101)\n",
    "clf_B = SVC(random_state = 101)\n",
    "clf_C = AdaBoostClassifier(random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set sample sizes\n",
    "samples_1 = int(round(len(X_train) / 100))\n",
    "samples_10 = int(round(len(X_train) / 10))\n",
    "samples_100 = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Collect results for various sample sizes\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]: # Define which classifiers shall be used\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "- Grid-search is used to find the optimal hyperparameters of a model which results in the most ‘accurate’ predictions.\n",
    "- Grid-searching can be applied across machine learning to calculate the best parameters to use for any given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create the parameters list you wish to tune (depending on the model!)\n",
    "parameters = {'n_estimators':[50, 120],                \n",
    "              'learning_rate':[0.1, 0.5, 1.],               \n",
    "              'base_estimator__min_samples_split' : np.arange(2, 8, 2),               \n",
    "              'base_estimator__max_depth' : np.arange(1, 4, 1),\n",
    "              'base_estimator__min_child_weight' : np.arange(1, 4, 1)\n",
    "             } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit grid and print results\n",
    "# TODO: Make an fbeta_score scoring object\n",
    "scorer = make_scorer(fbeta_score,beta=0.5) \n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf,parameters,scorer) \n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(X_train,y_train) \n",
    "print(grid_fit.best_score_)\n",
    "print(grid_fit.best_params_)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_ \n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test) \n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search (Pipeline)\n",
    "In order to optimize our model we will use gird search. At first we have to define a parameter space we want to search for the best parameter combination. Then we have to initiate our grid search via GridSearchCV. The last step is to use the fit method providing our training data as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Defining parameter space for grid-search. Since we want to access the classifier step in our pipeline \n",
    "# we have to add 'logreg__' infront of the corresponding hyperparameters. \n",
    "param_logreg = {'logreg__penalty':('l1','l2'),\n",
    "                'logreg__C': [0.01, 0.1, 1, 10, 100]\n",
    "               }\n",
    "\n",
    "grid_logreg = GridSearchCV(pipeline, param_grid=param_logreg, cv=3, scoring='accuracy', \n",
    "                           verbose=5, n_jobs=-1) # scoring can also be \"precision\", \"recall\", ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "grid_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict values based on new parameters\n",
    "y_pred = grid_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_logreg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_logreg.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model as best_model\n",
    "best_model = grid_logreg.best_estimator_['logreg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "Finally we have a good model. Let's see if it also passes the final evaluation on the test data. Therefore we have to prepare the test set in the same way we did with the training data. Thanks to our pipeline it's done in a blink. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on Train/Test Predict/Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define formula for evaluation\n",
    "def evaluate_model(predictions, probs, train_predictions, train_probs):\n",
    "    \"\"\"Compare machine learning model to baseline performance.\n",
    "    Computes statistics and shows ROC curve.\"\"\"\n",
    "    \n",
    "    baseline = {}\n",
    "    \n",
    "    baseline['recall'] = recall_score(test_labels, [1 for _ in range(len(test_labels))])\n",
    "    baseline['precision'] = precision_score(test_labels, [1 for _ in range(len(test_labels))])\n",
    "    baseline['roc'] = 0.5\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['recall'] = recall_score(test_labels, predictions)\n",
    "    results['precision'] = precision_score(test_labels, predictions)\n",
    "    results['roc'] = roc_auc_score(test_labels, probs)\n",
    "    \n",
    "    train_results = {}\n",
    "    train_results['recall'] = recall_score(train_labels, train_predictions)\n",
    "    train_results['precision'] = precision_score(train_labels, train_predictions)\n",
    "    train_results['roc'] = roc_auc_score(train_labels, train_probs)\n",
    "    \n",
    "    for metric in ['recall', 'precision', 'roc']:\n",
    "        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(test_labels, [1 for _ in range(len(test_labels))])\n",
    "    model_fpr, model_tpr, _ = roc_curve(test_labels, probs)\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend();\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Call formula\n",
    "evaluate_model(predictions, probs, train_predictions, train_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on Preprocessor Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Preparing the test set \n",
    "preprocessor.fit(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the optimized model\n",
    "y_test_predicted = best_model.predict(X_test_preprocessed)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, y_test_predicted)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "Purpose: Communicate the findings with key stakeholders using plots and interactive visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Print metrics\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[2,4])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['class_1','class_2'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mean price on date\n",
    "data_results.groupby(\"date\")[\"price\"].mean().plot(kind=\"line\", x=\"date\", y=\"price\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Scatter Map for deviation from predicted value (all listings)\n",
    "fig = px.scatter_mapbox(data_results,\n",
    "                        lat=\"lat\",\n",
    "                        lon=\"long\",\n",
    "                        hover_name=\"price\",\n",
    "                        hover_data=[\"sqft_above\", 'floors'],\n",
    "                        size='price',\n",
    "                        color='res_rel',\n",
    "                        color_continuous_scale=[[0, \"rgb(255, 203, 100)\"],[0.5, \"rgb(116, 193, 185)\"],[1, \"rgb(116, 193, 185)\"]],\n",
    "                        color_discrete_sequence=[\"fuchsia\"],\n",
    "                        zoom=7,\n",
    "                        height=400)\n",
    "fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "#fig.write_html(\"html_fig/map_for_four_1.html\")   #saved as html in html_fig\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Density Map for deviation from predicted value (top 5 high grade listings)\n",
    "fig = px.density_mapbox(data_res_high,\n",
    "                        lat='lat',\n",
    "                        lon='long',\n",
    "                        z='res_rel',\n",
    "                        radius=5,\n",
    "                        color_continuous_scale=\"electric\" ,\n",
    "                        center=dict(lat=47.53, lon=-122.23),\n",
    "                        zoom=7,\n",
    "                        mapbox_style=\"open-street-map\")\n",
    "#fig.write_html(\"figures/map_price.html\")\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings and Recommendations\n",
    "Purpose: Summarize the key outcomes and findings of this project\n",
    "\n",
    "- xyz\n",
    "- xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "Purpose: Validate and extend findings of this project\n",
    "\n",
    "- Inclusion of further variables (e.g. ...)\n",
    "- Inclusion of further publicly available data (e.g. [Kaggle Competition](https://www.kaggle.com/kemical/kickstarter-projects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Further Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you might want to transform your features in a very specific way, which is not implemented in scikit-learn yet. In those cases you can create your very own custome transformers. In order to work seamlessly with everything scikit-learn provides you need to create a class and implement the three methods .fit(), .transform() and .fit_transform().\n",
    "Two useful base classes on which you can construct your personal transformer can be imported with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about building your own transformers or pipelines in general I would recommend to have a look at the following books:\n",
    "\n",
    "- Introduction to Machine Learning with Python by Müller and Guido (2017), Chapter 6\n",
    "- Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow by Geron (2019), Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links/Blogs\n",
    "- [Data Preprocessing Concepts (Theory)](https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825)\n",
    "- [Data Preprocession in Practice](https://towardsdatascience.com/data-preprocessing-in-python-b52b652e37d5)\n",
    "- [Pipeline in ML (SVM) with Scikit-learn: A Simple Example](https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976)\n",
    "- [Pipeline in ML (Decision Trees)](https://towardsdatascience.com/understanding-decision-tree-classification-with-scikit-learn-2ddf272731bd)\n",
    "- [Feature Engineering](https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html)\n",
    "- [Hyperparameters and Model Validation](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html)\n",
    "- [Grid Search for Model Tuning](https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
